{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newfrogg/data_engineering/blob/what_is_ELT/data_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is ELT ?"
      ],
      "metadata": {
        "id": "Cf76ae0IeEcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Engineering for short\n",
        "It's about the practice of designing and building systems with purposes:\n",
        "1. collecting,\n",
        "2. storing,\n",
        "3. analyzing data at scale.\n",
        "4. To ensure the highly usable state before being pushed to data scientists, data analysts.\n",
        "\n",
        "[Coursera-What is Data Engineering](https://www.coursera.org/articles/what-does-a-data-engineer-do-and-how-do-i-become-one)\n"
      ],
      "metadata": {
        "id": "2xn5RpTpae9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Data Engineering\n",
        "\"Data engineering is a set of operations aimed at creating ***interfaces and mechanisms for the flow and access of information***. It takes dedicated specialists—data engineers— to maintain data so that it remains available and usable by others. In short, data engineers set up and operate the organization’s data infrastructure, preparing it for further analysis by data analysts and scientists\"\n",
        "\n",
        "**-from “Data Engineering and Its Main Concepts” by AlexSoft**\n",
        "\n",
        "1. Data Engineering Defined\n",
        "\n",
        "Data engineering is the development, implementation, and maintenance of systems\n",
        "and processes that take in raw data and produce high-quality, consistent information that supports downstream use cases, such as analysis and machine learning. Data engineering is the intersection of security, data management, DataOps, data architecture, orchestration, and software engineering. A ***data engineer manages the data engineering lifecycle***, beginning with getting data from source systems and ending with serving data for use cases, such as analysis or machine learning.\n",
        "\n",
        "2. The Data Engineering Lifecycle\n",
        "\n",
        "- The data engineering lifecycle focus on data itself and shift away the conversation away from technology.\n",
        "- There are many stages (above and below the iceberge):\n",
        "    - Generation, Storage, Serving: tasks of data engineering workflow itself.\n",
        "    - Security, DataOps, Software Engineering: tasks for interact with relevant fields\n",
        "\n",
        "![Data Engineering Life Cycle](https://github.com/newfrogg/data_engineering/blob/what_is_ELT/images/data_engineering_life_cycle.png?raw=1)\n",
        "\n",
        "3. Evolution of the Data Engineer\n",
        "\n",
        "*   The roots of data engineering can be traced back to the **data warehousing era (1980s-2000)**, pioneered by figures like Bill Inmon and Ralph Kimball. Early roles like BI engineers and ETL developers focused on building systems for scalable analytics using relational databases and MPP systems-. The rise of the web introduced new data scale challenges that traditional systems struggled with.\n",
        "*   **Contemporary data engineering emerged in the early 2000s** as companies faced exploding data growth. Innovations from Google (GFS, MapReduce), the open-source Hadoop ecosystem inspired by Google's work, and the advent of public clouds like AWS provided the **foundation for distributed computation and storage** on massive clusters-. This marked the beginning of the \"big data\" era.\n",
        "*   The **big data era (2000s-2010s)** saw the rise of the \"big data engineer\" proficient in software development and low-level infrastructure hacking to manage complex open-source tools like Hadoop and Spark-. While powerful, managing these massive clusters was operationally burdensome and costly, often diverting engineers from delivering business value. The term \"big data\" has since become a relic as the technology became more accessible.\n",
        "*   In the **2020s, big data engineers are now simply called data engineers or data lifecycle engineers**, reflecting a shift towards managing the entire data engineering lifecycle rather than low-level infrastructure details-. With greater abstraction and simplification of tools, the focus has moved to higher-value areas like security, data management, DataOps, data architecture, and orchestration. Data engineering has become a discipline of **connecting various modular technologies** to serve business goals.\n",
        "\n",
        "4. Data Engineering and Data Science\n",
        "\n",
        "- There are many opinions abouth relationship between data engineering and data science. However, for this case, we consider that **data engineering is a separate discipline from data science and analytics**, although they are complementary. Data engineering is described as sitting **upstream** from data science, meaning data engineers are responsible for providing the necessary data inputs for data scientists.\n",
        "\n",
        "- Considering **Data Science Hierarchy of Needs** published in 2017 by Monica Rogati, which places AI and machine learning at the top, with foundational tasks like data movement, storage, collection, cleansing, and infrastructure at the bottom. The sources state that data scientists often spend a significant majority of their time, estimated at **70% to 80%, on these lower-level tasks** such as gathering, cleaning, and processing data. This occurs because data scientists are typically not trained to engineer production-grade data systems.\n",
        "\n",
        "![Data Science Hierarchy](https://github.com/newfrogg/data_engineering/blob/what_is_ELT/images/data_science_hierarchy.png?raw=1)\n",
        "\n",
        "- The core idea is that **data engineers build the solid data foundation** represented by the bottom layers of this hierarchy. By doing so, data engineers enable data scientists to focus their time more effectively on higher-value activities like analysis, experimentation, and machine learning (the top layers of the pyramid). Ultimately, data engineering bridges the gap between acquiring raw data and extracting value from it, playing a vital role in the success of data science in production environments.\n",
        "\n",
        "[Fundamentals of Data Engineering](https://soclibrary.futa.edu.ng/books/Fundamentals%20of%20Data%20Engineering%20(Reis,%20JoeHousley,%20Matt)%20(Z-Library).pdf)"
      ],
      "metadata": {
        "id": "Gvwe2gkoTv8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is ETL ?\n",
        "ETL is about a *data integration process* including:\n",
        "1. **Extract** data from legacy system\n",
        "2. **Transform** and/or clean data to enhance data quality, improve consitency\n",
        "3. **Load** data into target databases\n",
        "\n",
        "[IBM_ETL](https://www.ibm.com/think/topics/etl)\n",
        "\n"
      ],
      "metadata": {
        "id": "RBSCyNIkeHxL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}